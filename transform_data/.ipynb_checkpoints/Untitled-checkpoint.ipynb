{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms ,datasets , utils \n",
    "\n",
    "key_pts_frame = pd.read_csv('/content/training_frames_keypoints.csv')\n",
    "#print(len(key_pts_frame))\n",
    "\n",
    "n = 0\n",
    "img_name = key_pts_frame.iloc[n,0]\n",
    "key_pts = key_pts_frame.iloc[n,1:].as_matrix()\n",
    "key_pts = key_pts.astype('float').reshape(-1,2)\n",
    "'''print('Image name: ', img_name)\n",
    "print('Landmarks shape: ', key_pts.shape)\n",
    "print(f'First 4 key pts: {key_pts[:4]}')\n",
    "\n",
    "# print out some stats about the data\n",
    "print('Number of images: ', key_pts_frame.shape)\n",
    "print(key_pts)'''\n",
    "#Number of images:  (3462, 137) NOTE: name of the image is included so column size is 137\n",
    "\n",
    "def show_keypoints(img = img_name,  keypoints = key_pts):\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.scatter(keypoints[:,0], keypoints[:,1], s = 20, marker = '.', c = 'm')\n",
    "    plt.show()\n",
    "\n",
    "#show_keypoints(mpimg.imread(os.path.join('/media/mrugank/626CB0316CB00239/for development purpose only/python/computer_vision/cvnd_exercises-master/p1_facial_keypoints-master/P1_Facial_Keypoints-master/data/training/', img_name)))\n",
    "\n",
    "class FacialKeyPointDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "        self.key_pts_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.key_pts_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.key_pts_frame.iloc[idx,0])\n",
    "        img = mpimg.imread(img_name)\n",
    "\n",
    "        if img.shape[2] == 4:\n",
    "            img = img[:,:,0:3]\n",
    "\n",
    "        key_pts = key_pts_frame.iloc[idx, 1:].as_matrix()\n",
    "        key_pts = key_pts.astype('float').reshape(-1,2)\n",
    "        sample = {'image_name':self.key_pts_frame.iloc[idx,0], 'image': img, 'key_points': key_pts}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "'''face_dataset = FacialKeyPointDataset(csv_file = '/media/mrugank/626CB0316CB00239/for development purpose only/python/computer_vision/cvnd_exercises-master/p1_facial_keypoints-master/P1_Facial_Keypoints-master/data/training_frames_keypoints.csv', root_dir = '/media/mrugank/626CB0316CB00239/for development purpose only/python/computer_vision/cvnd_exercises-master/p1_facial_keypoints-master/P1_Facial_Keypoints-master/data/training/')\n",
    "\n",
    "print('length of dataset', len(face_dataset))\n",
    "print(type(face_dataset))\n",
    "\n",
    "num_to_disp = 3\n",
    "for i in range(num_to_disp):\n",
    "    #define the size of image\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    #random select sample\n",
    "    rand_i = np.random.randint(0, len(face_dataset))\n",
    "    sample = face_dataset[rand_i]\n",
    "\n",
    "    # print relevant info about the image\n",
    "    print(f\"i = {i}, image_name = {sample['image_name']}, image_shape = {sample['image'].shape}, key_points_shape = {sample['key_points'].shape}\")\n",
    "\n",
    "    show_keypoints(img = sample['image'], keypoints = sample['key_points'])'''\n",
    "\n",
    "\n",
    "\n",
    "## Apllying Transformation ##\n",
    "\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Convert a color image to grayscale and normalize the color range to [0,1].\"\"\"        \n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['key_points']\n",
    "        \n",
    "        image_copy = np.copy(image)\n",
    "        key_pts_copy = np.copy(key_pts)\n",
    "\n",
    "        # convert image to grayscale\n",
    "        image_copy = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # scale color range from [0, 255] to [0, 1]\n",
    "        image_copy=  image_copy/255.0\n",
    "        \n",
    "        # scale keypoints to be centered around 0 with a range of [-1, 1]\n",
    "        # mean = 100, sqrt = 50, so, pts should be (pts - 100)/50\n",
    "        key_pts_copy = (key_pts_copy - 100)/50.0\n",
    "        #print('key_pts', key_pts)\n",
    "        #print('key_pts_copy',key_pts_copy)\n",
    "\n",
    "\n",
    "        return {'image': image_copy, 'key_points': key_pts_copy}\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['key_points']\n",
    "\n",
    "        #print('output size', self.output_size)\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        #print('h, w', h, w)\n",
    "        #print('key points', key_pts)\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                scale = float(w / self.output_size)\n",
    "                new_h, new_w = h / scale, self.output_size\n",
    "            else:\n",
    "                scale = float(h / self.output_size)\n",
    "                new_h, new_w = self.output_size, w / scale\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "        #print('new_h, new_w', new_h, new_w)\n",
    "        \n",
    "        # scale the pts, too\n",
    "        key_pts = key_pts / [scale, scale]\n",
    "        #print('scaled key points', key_pts)\n",
    "\n",
    "        return {'image': img, 'key_points': key_pts}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['key_points']\n",
    "\n",
    "        #print('random_crop_size', self.output_size)\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        #print('h, w', h, w)\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        #print('x, y', top, left)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        #print('before changing key_pts', key_pts)\n",
    "\n",
    "        key_pts = key_pts - [left, top]\n",
    "\n",
    "        #print('after changing key_pts', key_pts)\n",
    "\n",
    "        return {'image': image, 'key_points': key_pts}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['key_points']\n",
    "         \n",
    "        # if image has no grayscale color channel, add one\n",
    "        if(len(image.shape) == 2):\n",
    "            # add that third color dim\n",
    "            image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "            \n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'key_points': torch.from_numpy(key_pts)}\n",
    "\n",
    "# test out some of these transforms\n",
    "'''rescale = Rescale(100)\n",
    "crop = RandomCrop(50)\n",
    "composed = transforms.Compose([Rescale(250),\n",
    "                               RandomCrop(224)])\n",
    "\n",
    "# apply the transforms to a sample image\n",
    "test_num = 500\n",
    "sample = face_dataset[test_num]\n",
    "\n",
    "fig = plt.figure()\n",
    "for i, tx in enumerate([rescale, crop, composed]):\n",
    "    transformed_sample = tx(sample)\n",
    "\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tx).__name__)\n",
    "    show_keypoints(transformed_sample['image'], transformed_sample['key_points'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "data_transfer = transforms.Compose([Rescale(250), RandomCrop(224), Normalize(), ToTensor()])\n",
    "\n",
    "transformed_dataset = FacialKeyPointDataset(csv_file = '/media/mrugank/626CB0316CB00239/for development purpose only/python/computer_vision/cvnd_exercises-master/p1_facial_keypoints-master/P1_Facial_Keypoints-master/data/training_frames_keypoints.csv', root_dir = '/media/mrugank/626CB0316CB00239/for development purpose only/python/computer_vision/cvnd_exercises-master/p1_facial_keypoints-master/P1_Facial_Keypoints-master/data/training/', transform = data_transfer)\n",
    "\n",
    "# print some stats about the transformed data\n",
    "print('Number of images: ', len(transformed_dataset['key_points']))\n",
    "\n",
    "# make sure the sample tensors are the expected size\n",
    "for i in range(1):\n",
    "    sample = transformed_dataset[i]\n",
    "    print(i, sample['image'].shape, sample['key_points'].shape)\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
