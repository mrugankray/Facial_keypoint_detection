{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler \n",
    "from torchvision import models, transforms\n",
    "from transform_data.face_keypoint_det import FacialKeyPointDataset, Normalize, Rescale, RandomCrop, ToTensor\n",
    "import numpy as np\n",
    "# dataset #\n",
    "data_transform = transforms.Compose([Rescale(250), RandomCrop(224), Normalize(), ToTensor()])\n",
    "\n",
    "transformed_train_dataset = FacialKeyPointDataset(csv_file = '/content/training_frames_keypoints.csv', root_dir = '/content/training/', transform = data_transform)\n",
    "\n",
    "transformed_test_dataset = FacialKeyPointDataset(csv_file = '/content/test_frames_keypoints.csv', root_dir = '/content/test/', transform = data_transform)\n",
    "\n",
    "print('length of dataset', len(transformed_train_dataset))\n",
    "print(type(transformed_train_dataset))\n",
    "\n",
    "# training indices used for validation #\n",
    "len_dataset = len(transformed_train_dataset)\n",
    "indices = list(range(len_dataset))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(0.2*len_dataset))\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# trn_sampler #\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# training loader #\n",
    "num_workers = 4\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(transformed_train_dataset, num_workers = num_workers, batch_size = batch_size , sampler = train_sampler)\n",
    "\n",
    "val_loader = DataLoader(transformed_train_dataset, num_workers = num_workers, batch_size = batch_size, sampler = val_sampler)\n",
    "\n",
    "test_loader = DataLoader(transformed_test_dataset, num_workers = num_workers, batch_size = batch_size , shuffle = True)\n",
    "\n",
    "# checking if gpu is available #\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "# defining model architecture\n",
    "model = models.vgg11_bn(pretrained=False)\n",
    "\n",
    "# redesigning the classifier part to output 136 features and the convolution part to accept grayscale image\n",
    "from collections import OrderedDict\n",
    "model.features[0] = nn.Conv2d(1,64, 3, stride=(1,2), padding=(1,1))\n",
    "print(model.features[0])\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(25088, 4096)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.5)),\n",
    "    ('fc2', nn.Linear(4096, 4096)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('dropout2', nn.Dropout(0.5)),\n",
    "    ('fc3', nn.Linear(4096, 1000)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('dropout3', nn.Dropout(0.5)),\n",
    "    ('fc4', nn.Linear(1000, 136))\n",
    "]))\n",
    "model.classifier = classifier\n",
    "print(model)\n",
    "\n",
    "# defining loss funcion #\n",
    "criterion = nn.CrossEntropyLoss\n",
    "\n",
    "# defining optimizer #\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "if device == 'cuda':\n",
    "    model = model.cuda()\n",
    "\n",
    "print(device)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "test_loss_list = []\n",
    "val_min_loss = np.Inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    trn_loss = 0\n",
    "    test_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    trn_running_loss = 0\n",
    "    test_running_loss = 0\n",
    "    val_running_loss = 0\n",
    "\n",
    "    for trn_i, trn_sample in enumerate(train_loader):\n",
    "\n",
    "        # move all images and labels to the gpu if the system has a gpu\n",
    "        trn_img = trn_sample['image']\n",
    "        trn_key_pts = trn_sample['key_points']\n",
    "        # flatten key points\n",
    "        trn_key_pts = trn_key_pts.view(trn_key_pts.shape[0], -1)\n",
    "        if device == 'cuda':\n",
    "            trn_key_pts = trn_key_pts.type(torch.cuda.FloatTensor)\n",
    "            trn_img = trn_img.type(torch.cuda.FloatTensor)\n",
    "            trn_img = trn_img.to(device)\n",
    "            trn_key_pts = trn_key_pts.to(device)\n",
    "\n",
    "        # sets optimizer to zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # log probability\n",
    "        trn_log_ps = model(trn_img)\n",
    "\n",
    "        # computing loss\n",
    "        loss_trn = criterion(trn_log_ps, trn_key_pts)\n",
    "\n",
    "        # backward propagation\n",
    "        loss_trn.backward()\n",
    "\n",
    "        # optimize the loss\n",
    "        optimizer.step()\n",
    "\n",
    "        # adding training loss at each image\n",
    "        trn_running_loss += loss_trn.item()\n",
    "\n",
    "    else:\n",
    "        with torch.no_grad:\n",
    "            # setting model to evaluation mode so that dropout does not ocur while we train the model\n",
    "            model.eval()\n",
    "\n",
    "            for val_i, val_sample in enumerate(val_loader):\n",
    "                val_img = val_sample['images']\n",
    "                val_label = val_sample['key_points']\n",
    "                # flatten key points\n",
    "                val_label = val_label.view(val_label.shape[0], -1)\n",
    "                if device == 'cuda':\n",
    "                    val_label = val_label.type(torch.cuda.FloatTensor)\n",
    "                    val_img = val_img.type(torch.cuda.FloatTensor)\n",
    "                    val_img = val_img.to(device)\n",
    "                    val_label = val_label.to(device)\n",
    "\n",
    "                loss_val = criterion(val_img, val_label)\n",
    "\n",
    "                val_running_loss += loss_val.item()\n",
    "\n",
    "            for test_i, test_sample in test_loader:\n",
    "                test_img = test_sample['images']\n",
    "                test_label = test_sample['key_points']\n",
    "                # flatten key points\n",
    "                test_label = test_label.view(test_label.shape[0], -1)\n",
    "                if device == 'cuda':\n",
    "                    test_label = test_label.type(torch.cuda.FloatTensor)\n",
    "                    test_img = test_img.type(torch.cuda.FloatTensor)\n",
    "                    test_img = test_img.to(device)\n",
    "                    test_label = test_label.to(device)\n",
    "                \n",
    "                loss_test = criterion(test_img, test_label)\n",
    "\n",
    "                test_running_loss += loss_test.item()\n",
    "\n",
    "        trn_loss = trn_running_loss / len(train_loader)\n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "        test_loss = test_running_loss / len(test_loader)\n",
    "\n",
    "        trn_loss_list = trn_loss_list.append(trn_loss)\n",
    "        val_loss_list  = val_loss_list.append(val_loss)\n",
    "        test_loss_list = test_loss_list.append(test_loss)\n",
    "\n",
    "        print(f'epochs: {i+epoch} / {epochs}, training_loss: {trn_loss}, val_loss: {val_loss}, test_loss: {test_loss}')\n",
    "\n",
    "        # setting model to training mode \n",
    "        model.train()\n",
    "\n",
    "        if val_loss <= val_min_loss:\n",
    "            print(f'validation loss decreased {val_loss} ---> {val_min_loss}. Saving model...')\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "            val_min_loss = val_loss\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
